# Any passwords and credentials in this file should be encrypted

# All default properties for stack "dev" instance "${org.sagebionetworks.developer}" belong in this file

#---- Endpoint configuration
org.sagebionetworks.authenticationservice.privateendpoint=${org.sagebionetworks.authenticationservice.privateendpoint}
org.sagebionetworks.authenticationservice.publicendpoint=${org.sagebionetworks.authenticationservice.publicendpoint}
org.sagebionetworks.repositoryservice.endpoint=${org.sagebionetworks.repositoryservice.endpoint}
org.sagebionetworks.fileservice.endpoint=${org.sagebionetworks.fileservice.endpoint}
org.sagebionetworks.bridgeservice.endpoint=${org.sagebionetworks.bridgeservice.endpoint}
org.sagebionetworks.searchservice.endpoint=${org.sagebionetworks.searchservice.endpoint}
org.sagebionetworks.portal.endpoint=${org.sagebionetworks.portal.endpoint}

#--- The main MySQL database connection.
org.sagebionetworks.repository.database.connection.url=jdbc:mysql://localhost/dev${org.sagebionetworks.developer}
org.sagebionetworks.repository.database.username=dev${org.sagebionetworks.developer}
org.sagebionetworks.repository.database.password=tK15UbS9itkodIYeyDQpQA==

#--- The database information used to create ids.
org.sagebionetworks.id.generator.database.connection.url=jdbc:mysql://localhost/dev${org.sagebionetworks.developer}
org.sagebionetworks.id.generator.database.username=dev${org.sagebionetworks.developer}
org.sagebionetworks.id.generator.database.password=tK15UbS9itkodIYeyDQpQA==

#---- S3 configuration

# This is the bucket for Synapse data
org.sagebionetworks.s3.readAccessExpiryHours=24
org.sagebionetworks.s3.writeAccessExpiryHours=24
# This is for attachment URLs that expire in 10 seconds.
org.sagebionetworks.s3.readAccessExpirySeconds=20
org.sagebionetworks.s3.bucket=devdata.sagebase.org

# This is the shared bucket for all backup files.
org.sagebionetworks.shared.s3.backup.bucket=shared.backups.sagebase.org

# This is the bucket for workflow-related files such as configuration or search document files.
# Each workflow should store stuff under its own workflow name prefix so that we can configure 
# permissions not only on the bucket but also the S3 object prefix.
org.sagebionetworks.s3.bucket.workflow=devworkflow.sagebase.org

#The amount of time (MS) the ChangeSentMessageSynchWorker sleeps between pages.
org.sagebionetworks.worker.change.synch.sleep.ms=2000
# The minium page size used by ChangeSentMessageSynchWorker. (25K)
org.sagebionetworks.worker.change.synch.min.page.size=25000

#--- encrypted values (passwords, credentials):
#
# to generate an encrypted property value:
# cd lib/stackConfiguration
# mvn exec:java --define exec.mainClass="org.sagebionetworks.StringEncrypter" --define exec.args="encrypt <common-encryption-key-for-stack> <MySecretPassword>"
# returns 
# MySecretPassword -> PZnry4SROFQVIq1up8DIt8uxV8TkD0Ve
# The actual encryption key is saved in work/platform/PasswordsAndCredentials/platformPropertyEncryptionKey.txt


org.sagebionetworks.id.generator.database.driver=com.mysql.jdbc.Driver
org.sagebionetworks.repository.databaes.driver=com.mysql.jdbc.Driver
org.sagebionetworks.table.databaes.driver=com.mysql.jdbc.Driver

# The repository database connection pool properties.
org.sagebionetworks.pool.connection.validate=true
# This is the SQL that will be used to determine if a connection is alive.
org.sagebionetworks.pool.connection.validate.sql=SELECT 1
# The minimum number of connections maintained by the connection pool.
org.sagebionetworks.pool.min.number.connections=2
# The maximum number of connections the connection pool will created
org.sagebionetworks.pool.max.number.connections=40

# The repository Apache HttpClient connection pool properties
org.sagebionetworks.httpclient.connectionpool.maxconnsperroute=20

# JDOPersistenceManager configuration properties.
javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.jdo.JDOPersistenceManagerFactory
datanucleus.NontransactionalRead=true
datanucleus.NontransactionalWrite=true
javax.jdo.option.RetainValues=true
datanucleus.autoCreateSchema=true
datanucleus.validateConstraints=false
datanucleus.validateTables=false
datanucleus.transactionIsolation=read-committed

# Used in conjunction with the API key below to login as the migration admin user
org.sagebionetworks.migration.admin.username=migrationAdmin@sagebase.org
# Note: This API key should be changed in before bootstrapping the migration admin in production systems
org.sagebionetworks.migration.admin.apikey=FvSRyISU5o+qq8TJNmR9YPEZBb4L1ZxLX/Utu779riXwgGp2hX/QXzrmA6RSTF8n1esmATUXdOwpcU5vQPwB7XFTL9nzkIMukJREz/h4SY4zCnxpOsAzayh0hh7INClA

# Email address used to send notifications
org.sagebionetworks.notification.email.address=notifications@sagebase.org

# Email address used to send to Synapse Ops team
org.sagebionetworks.synapseops.email.address=synapse-ops@sagebase.org

# Activity Logger
org.sagebionetworks.usage.metrics.logging.enabled=true

# Whether log sweeping should be enabled
org.sagebionetworks.logging.sweeper.enabled=true
org.sagebionetworks.logging.sweeper.delete.enabled=true
org.sagebionetworks.logging.sweeper.bucket=logs.sagebase.org

#AmazonWebServices CloudWatch Profiler 
org.sagebionetworks.cloud.watch.report.enabled=true

#AmazonWebServices CloudWatch Profiler's Trigger time in milliseconds
org.sagebionetworks.cloud.watch.trigger=60000

#Call Performance Profiler 
org.sagebionetworks.call.performance.report.enabled=true

#Calll Performance Profiler's Trigger time in milliseconds
org.sagebionetworks.call.performance.trigger=60000

# The maximum number of threads used by the backup/restore daemon thread pool.
# Set this to an even number since two threads are used for each daemon.
org.sagebionetworks.backup.restore.thread.pool.maximum=10

# The maximum number of bytes allowed for a query result.  Currently set to 500 KB.
org.sagebionetworks.maximum.bytes.per.query.result=512000

# The maximum number entities returned in a single call
org.sagebionetworks.maximum.number.entities.returned.per.call=20

# This is a size limit on a single entity.
# Note: The number can never be decreased, so increase with care.
org.sagebionetworks.maximum.number.bytes.per.entity=1024000

# The maximum number of pixels used for a preview image
org.sagebionetworks.preview.image.max.width.pixels=425
org.sagebionetworks.preview.image.max.height.pixels=200
org.sagebionetworks.attachment.preview.image.max.pixels=150

# Google email address for receiving Breast Cancer Challenge applications
org.sagebionetworks.bcc.approvalEmail=integration.test@sagebase.org

# a switch to disable the BCC Signup element of the Web UI
org.sagebionetworks.bcc.signup.enabled=true

org.sagebionetworks.bridge.spreadsheet.title=Bridge Spreadsheet

# the Consumer Key and Secret were set up using Admin tools for our Google hosted domain
org.sagebionetworks.bcc.googleapps.oauth.consumer.key=sagebase.org
# encrypted
org.sagebionetworks.bcc.googleapps.oauth.consumer.secret=eFRrk1D5T0XerPxoS3J0HcxyT6GOYPiEKHSGHsg0KUA=

# the following are generated using OAuthUtils.generateAccessToken()
# encrypted
org.sagebionetworks.bcc.googleapps.oauth.access.token=5nDka+sq5WHm7RZaLeKn5Nd2948HN/wFbYEDswD5Iep9/PFoLQ2tKTyO8xCVSN8W
#encrypted
org.sagebionetworks.bcc.googleapps.oauth.access.token.secret=M4guxd8yMXCzqapmIriChh0S+jhAHat/KHSGHsg0KUA=

# AWS Simple work flow settings:
org.sagebionetworks.swf.workflowExecutionRetentionPeriodInDays=1

# Portal LinkedIn Integration (secret in AWS stack specific configuration files)
org.sagebionetworks.portal.api.linkedin.key=0oq37ippxz8c
# Portal Get Satisfaction Integration
org.sagebionetworks.portal.api.getsatisfaction.key=z5e1lo36kro5

#encrypted
org.sagebionetworks.portal.api.linkedin.secret=YLUPEqtJfj90WngxCkqApih0hh7INClA
#encrypted
org.sagebionetworks.portal.api.getsatisfaction.secret=RmKXqRvGxYeN3yciA1P4TvCJueNgGApBWnwQGscV/a8odIYeyDQpQA==

org.sagebionetworks.repo.manager.jira.user.name=synapse-jira-service
org.sagebionetworks.repo.manager.jira.user.password=6PkUHq9yaYlIqlIZCUn0jmmR4IG0y8b+

org.sagebionetworks.bridge.data.encryptionkey=todo
org.sagebionetworks.bridge.data.mapping.encryptionkey=todo

# The percentage of the maximum memory that can be used for file transfer.
# Note: transfer% + preview% cannot exceed 90%
org.sagebionetworks.repo.manager.file.transfer.memory.percent.of.max=0.70
# The percentage of the maximum memory that can be used for preview generation.
# Note: transfer% + preview% cannot exceed 0.90 (90%)
org.sagebionetworks.repo.manager.file.preview.memory.percent.of.max=0.20
# This is the size of a single file transfer memory block used as a buffer. 
# Note: Due to S3 limitations on the minimum size of a single part of a multi-part upload
# this value cannot be less 5 MB.  It is currently set to 5 MB.
org.sagebionetworks.repo.manager.file.transfer.memory.buffer.bytes=5242880
# The maximum number of worker threads used to generate preview files.
org.sagebionetworks.file.preview.max.number.worker.threads=10
# The maximum number of entities that can be moved into the trash can at one time.
org.sagebionetworks.repo.manager.trash.max.trashable=2000

# Should messages be published to the AWS topic?
org.sagebionetworks.repo.manage.shouldMessagesBePublishedToTopic=true

#--- EZID ---
org.sagebionetworks.ezid.username=apitest
org.sagebionetworks.ezid.password=vab8LnWEFVc=
org.sagebionetworks.ezid.url=https://ezid.cdlib.org/
org.sagebionetworks.ezid.doi.prefix=doi:10.5072/FK2.
org.sagebionetworks.ezid.doi.target.url.prefix=https://www.synapse.org

# Backup batch size See PLFM-1896
org.sagebionetworks.repo.manager.migration.backup.batch.max=500

# This should match the Database max_allowed_packet value. See PLFM-1900
org.sagebionetworks.repo.model.dbo.migration.max.allowed.packet.byte = 1048576

# Enable the CloudSearch features
org.sagebionetworks.search.enabled=false
# Enable Dynamo related features
org.sagebionetworks.dynamo.enabled=false
# Enable Table related features
org.sagebionetworks.table.enabled=false
# Enalb DOI related features
org.sagebionetworks.doi.enabled=false

# The maximum number of bytes per HTTP table request.  Currently set to 2 MB which matches
# Tomcat's max bytes per POST
org.sagebionetworks.table.max.bytes.per.request=2097152
# The maximum number of bytes in a single table change set file.  Currently set to 5 MB.
org.sagebionetworks.table.max.bytes.per.change.set=5242880
# The maximum number of possible enum values for one column.
org.sagebionetworks.table.max.enum.values=100

# The maximum amount of time in MS that the table worker can hold the semaphore lock on the table.

# Note: If this is set too short the lock could be released while the table is still being updated.
org.sagebionetworks.table.worker.timeout.ms= 3600000
# The timeout for querying a table. Currently set to 15 seconds.
org.sagebionetworks.table.read.timeout.ms=15000

# Configuration properties for the Semaphore gated runner.

# When a lock is acquired from the semaphore a timeout must be provided
# If the lock is not released before the timeout expires, the lock will be forfeit
# and another runner will be able to acquire the lock. This is currently set to
# 30 minutes to allow plenty of time for the works to finish their work.
# Setting this too low will undermine the gating.
org.sagebionetworks.semaphore.gated.lock.timeout.ms=1800000
# The maximum number of worker in the cluster that will process RDS index data
org.sagebionetworks.semaphore.gated.max.runners.rds=1
# The maximum number of worker in the cluster that will send messages to users
org.sagebionetworks.semaphore.gated.max.runners.message.to.user=2
# The maximum number of worker in the cluster that will process search index data
org.sagebionetworks.semaphore.gated.max.runners.search=10
# The maximum number of worker in the cluster that will process file previews
org.sagebionetworks.semaphore.gated.max.runners.file.preview=10
# The maximum number of worker in the cluster that will process Dynamo index data
org.sagebionetworks.semaphore.gated.max.runners.dynamo.index=10
# The maximum number of worker in the cluster that will synchronize Dynamo with RDS
org.sagebionetworks.semaphore.gated.max.runners.dynamo.synchronize=1
# The maximum number of worker in the cluster that will process Annotations data
org.sagebionetworks.semaphore.gated.max.runners.annotations=1
# The maximum number of workers in the cluster that will push UnsentMessageRanges to SQS
org.sagebionetworks.semaphore.gated.max.runners.unsent.message.queuer=1
# The maximum number of workers in the cluster that will pop UnsentMessageRanges from SQS
org.sagebionetworks.semaphore.gated.max.runners.unsent.message.poppers=1
# The maximum number of workers in the cluster that will pop UnsentMessageRanges from SQS
org.sagebionetworks.semaphore.gated.max.runners.principal.header.filler=1
# The maximum number of workers in the cluster that will pop Table update messages from SQS
org.sagebionetworks.semaphore.gated.max.runners.table.cluster=10

# The maximum timeout for an exclusive lock in milliseconds. Set to one hour.
org.sagebionetworks.semaphore.exclusive.max.timeout.ms=3600000

# The maximum timeout for a shared lock in milliseconds. Set to 2 mins.
org.sagebionetworks.semaphore.shared.max.timeout.ms=120000

#The maximum amount of time the multipart upload daemons are allowed to take before timing out.
org.sagebionetworks.repo.manager.file.multipart.upload.daemon.timeout.ms=300000
# The maximum number of threads that can be used for the mutipart upload daemons.
org.sagebionetworks.repo.manager.file.multipart.upload.daemon.main.max.threads=20
# The maximum number of threads that can be used for the mutipart upload daemons copy part sub-task.
org.sagebionetworks.repo.manager.file.multipart.upload.daemon.copy.part.max.threads=50

org.sagebionetworks.repo.model.bootstrap.root.folder.entity.path=/root
org.sagebionetworks.repo.model.bootstrap.root.folder.entity.id=4489
org.sagebionetworks.repo.model.bootstrap.trash.folder.entity.path=/root/trash
org.sagebionetworks.repo.model.bootstrap.trash.folder.entity.id=1681355

# The maximum number of concurrent connections on repo for one synapse user over the cluster
org.sagebionetworks.max.concurrent.repo.connections=10
